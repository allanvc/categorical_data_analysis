---
title: "Exemplos de Regressão Logística em R"
subtitle: "Análise de Dados Categorizados"
author: "Allan Vieira 14/0128492"
date: "May 8, 2018"
output:
  html_document:
    self_contained: false
    df_print: paged
  pdf_document: default
---

<!-- self_contained: false --- para nao dar pau do plotly com firefox -->
<!-- df_print para as formas de imprimir data frames e tibbles -->
<!-- ver https://rmarkdown.rstudio.com/html_document_format.html -->

<!-- incluir no cabecalho: -->
<!-- always_allow_html: yes  -->
<!--para quando formos passar para pdf -->

<style>
body {
text-align: justify}
</style>

<!-- para justificar texto no markdown -->
<!-- https://stackoverflow.com/questions/43222169/how-to-justify-the-text-to-both-sides-when-knitting-html-in-rmarkdown -->

<!-- <style> -->
<!--   .col2 { -->
<!--     columns: 2 200px;         /* number of columns and width in pixels*/ -->
<!--     -webkit-columns: 2 200px; /* chrome, safari */ -->
<!--     -moz-columns: 2 200px;    /* firefox */ -->
<!--   } -->
<!--   .col3 { -->
<!--     columns: 3 100px; -->
<!--     -webkit-columns: 3 100px; -->
<!--     -moz-columns: 3 100px; -->
<!--   } -->
<!-- </style> -->
<!-- esse de cima funciona no output do RStudio, mas nao nos browsers -->
<!-- tb em: https://stackoverflow.com/questions/31753897/2-column-section-in-r-markdown -->


---

---

### 1. Exemplo das Abelhas

---


#### **i) ajuste do modelo**


**Preparação dos dados**:

```{r}
dados <- c(1.6907, 6, 59, 1.7242, 13, 60, 1.7552, 18, 62, 1.7842, 28, 56,
             1.8113, 52, 63, 1.8369, 53, 59, 1.8610, 61, 62, 1.8839, 59, 60)

beetles <- matrix(dados, ncol=3, byrow = TRUE)

colnames(beetles) <- c("dose", "killed", "total")

# criando uma coluna do outro resultado: x = 1 (survived); x = 0 (killed)
beetles <- cbind(beetles, beetles[,"total"] - beetles[,"killed"])
colnames(beetles)[4] <- c("survived")

tibble::as.tibble(beetles)
```

\s\s

**Ajuste do modelo**:

```{r}
resposta <- beetles[,c("killed", "survived")]
dose <- beetles[,"dose"]

bee_logit_model <- glm(resposta ~ dose, family=binomial(link="logit"))

summary(bee_logit_model)

```

\s\s

**Model Fit Statistics**:

```{r}
# AIC - no output do modelo ou via:
AIC(bee_logit_model)

# -2 Log L
-2*logLik(bee_logit_model)

```




**Plot da curva logística/modelo:**

```{r}
# plot:
# criando um conjunto com varios nros entre 1.65 e 1.9
# preenchendo todo o range entre valor max e min dos dados para a curva logística ficar suavizada
xx=1.65 +(0:250)/1000 
predictors=coef(bee_logit_model)[1]+coef(bee_logit_model)[2]*xx

# probabilidades e proporções (para o plot)
prob=exp(predictors)/(1+exp(predictors))

prop <- beetles[,"killed"]/ beetles[,"total"]

# com ggplot2
# library(ggplot2)
# ggplot()+
#   geom_point(aes(x=dose, y=prop), colour="purple")+
#   geom_line(aes(x=xx, y=prob), colour="blue")+
#   ggtitle( 'Curva Logística Ajustada' )+
#   theme(plot.title = element_text(hjust=0.5))
```

```{r, fig.width=9}
# ou com plotly:
library(magrittr)
# pontos e linhas no mesmo plot:
# https://plot.ly/r/line-and-scatter/
p1 <- plotly::plot_ly(x = ~dose, y = ~prop, name = 'prop', type = 'scatter', mode = 'markers') %>%
  plotly::add_trace(x= ~xx, y = ~prob, name = 'prob', mode = 'lines') %>%
  plotly::layout(title = "Curva Logística Ajustada")

p1
```


---

#### **ii) testes para $\beta$**

\s\s

**Testes de hipótese:**

```{r, message=FALSE}
# testes para existência de regressão

# 1) razao de verossimilhancas
library(lmtest)
lrtest(bee_logit_model) # ok! os resultados batem e sao significativos (rejeita H0)

# 2) teste de Wald
waldtest(bee_logit_model)
```

\s\s

Uma vez que ambos os testes indicam que os $\beta$'s são significantes, há evidências da existência de regressão logística entre a morte de abelhas e a dosagem do produto utilizado.

**Intervalos de Confiança:**

Para $log(odds)$:

```{r}
# IC log(odds)
# summary(bee_logit_model)
# IC_B <- bee_logit_model$coefficients[2] + c(-1,1)*qnorm(0.975)*2.8939

# ou
confint.default(bee_logit_model)

```

\s\s

O método *.default* assume normalidade assintótica, por isso é utilizado.

Para *odds ratio*:

```{r}
# IC (odds ratio)

exp(confint.default(bee_logit_model))

```


---

#### **iii) Goodness of Fit**


Na saída da função `glm()` ( e também no `summary(model)`) já temos algumas medidas de *goodness of fit*, como *Deviance* por exemplo.

```{r}
bee_logit_model
# ou
summary(bee_logit_model)

```

\s\s

**Deviance:**

Na verdade, o *output* do modelo nos dá duas medidas de *Deviance*: a *null deviance* e a *residual deviance*. Quanto mais baixa for a *deviance* de um modelo, melhor é o seu ajuste aos dados. Dito isso, a *null deviance* nos mostra quão bem a variável resposta é explicada/predita por um modelo logístico contendo somente o intercepto $\alpha$.  Já a *residual deviance* mostra em quanto **reduziu** nossa *deviance* ao introduzirmos a(s) variável(eis) explicativa(s) em nosso modelo. No caso, nota-se que há uma redução de aproximadamente $8.64$ de magnitude na *deviance* em comparação com a deviance do modelo nulo ao custo de $1$ grau de liberdade. Portanto, a introdução da variável *dose* melhororu o ajuste de nosso modelo.


Os *deviance residuals* também são uma informação importante, pois, se apresentarem valores muito altos, indicam mau ajuste do modelo. A saída de de `summary(modelo)` no **R**, nos traz estatísticas descritivas sobre estes resíduos. Como se vê, o valor máximo não passa de 2 ou 3 de magnitude, indicando um bom ajuste. Contudo, se desejarmos verificar valor por valor do *deviance* podemos fazê-lo com:

```{r}
# resid(bee_logit_model) 
# ou
residuals(bee_logit_model) # deviance

```

\s\s

Podemos calcular também os valores dos resíduos de *Pearson*, os quais devem ser próximos dos valores dos resíduos *deviance* e também não ultrapassando uma magnitude de 2 ou 3.

```{r}
summary(bee_logit_model$residuals) # pearson

# residuals(bee_logit_model, type="working")
# ou
bee_logit_model$residuals

```

\s\s

##### **Teste de Hosmer e Lemeshow**:

Este teste também serve para avaliar a *goodness of fit* de um modelo. No **R**, podemos empregá-lo de várias formas.

A primeira delas seria utilizando o modelo a partir do qual ajustamos os dados na forma de tabela de frequências. Mas como nesse caso só temos 8 observações, temos que ajustar o parâmetro `g` (número de classes/intervalos) da função para um valor menor.

```{r, message=FALSE, warning=FALSE}
library(ResourceSelection)
hoslem.test(bee_logit_model$y, bee_logit_model$fitted.values, g=5)

```

\s\s

A segunda forma é ajustando um novo modelo com base nos dados expandidos com a variável resposta na forma de zeros e uns (0,1). Assim ganhamos mais graus de liberdade e, consequentemente mais "espaço" para os intervalos. Note que na saída do modelo, temos exatamente os mesmos valores de coeficientes e de p-valor, mas valores diferentes para AIC, *deviance* etc. Essa diferença deve-se justamente ao maior número de observações que temos agora.

```{r, message=FALSE}
# antes do teste, eh necessario transformar para zero e uns

# nao evento eh sobreviver
response_l <- lapply(1:nrow(beetles), function(i){
  killed <- rep(c(0,1), c(beetles[i,"survived"], beetles[i,"killed"])) # response
  dose <- rep(beetles[i,"dose"], length(killed)) # variable
  cbind(dose, killed)
})

response_m <- Reduce(rbind, response_l)

bee_logit_model2 <- glm(response_m[,2] ~ response_m[,1], family=binomial(link="logit"))

summary(bee_logit_model2) # os deviance, df e AIC diferentes vem devido ao nro de linhas (obs) no modelo expandido


```

\s\s

Para o teste, fazemos uma pequena aleração na função *HLfit()* do pacote **modEvA**. O objetivo é replicar os resultados apresentados no output do **SAS**. Os ajustes  são para solucionar um *bug* da função e para fazer com que ela retorne também uma tabela das partições que foram geradas para o teste. Esta função é a única (?) que tem retorno parecido com o do SAS porque permite escolher métodos diferentes para gerar os intervalos. No caso utilizamos `bin.method="quantile"`.

```{r, message=FALSE}
library(modEvA)
# alteração da função HLfit:
HLfit2 <- function (model = NULL, obs = NULL, pred = NULL, bin.method, n.bins = 10, fixed.bin.size = FALSE, min.bin.size = 15, min.prob.interval = 0.1, simplif = FALSE) {
  # version 1.5 (24 Jun 2015)
  
  if (!is.null(model)) {
    if (!is.null(obs)) message("Argument 'obs' ignored in favour of 'model'.")
    if (!is.null(pred)) message("Argument 'pred' ignored in favour of 'model'.")
    obs <- model$y
    pred <- model$fitted.values
  }  # end if model
  
  stopifnot(
    length(obs) == length(pred),
    obs %in% c(0, 1),
    pred >= 0,
    pred <= 1
  )
  
  bins <- getBins(obs = obs, pred = pred, bin.method = bin.method, n.bins = n.bins, fixed.bin.size = fixed.bin.size, min.bin.size = min.bin.size, min.prob.interval = min.prob.interval)
  n.bins <- nrow(bins$bins.table)
  
  # next 4 lines: adapted from hosmerlem function in http://www.stat.sc.edu/~hitchcock/diseaseoutbreakRexample704.txt
  observed <- xtabs(cbind(1 - obs, obs) ~ bins$prob.bin)
  expected <- xtabs(cbind(1 - pred, pred) ~ bins$prob.bin)
  chi.sq <- sum((observed - expected) ^ 2 / expected)
  p.value <- 1 - pchisq(chi.sq, df = n.bins - 2)
  rmse <- sqrt(mean((observed - expected) ^ 2))
  
  if (simplif) return(list(chi.sq = chi.sq, p.value = p.value, RMSE = rmse))
  
  # plotting loosely based on calibration.plot function in package PresenceAbsence
  # no plot -- nosso ajuste!
  
  # nosso ajuste: partition table
  partition <- data.frame(cbind(matrix(observed[,2]), matrix(expected[,2])), 
                          cbind(matrix(observed[,1]), matrix(expected[,1])))
  
  #str(partition)
  colnames(partition) <- c("Observed_Event", "Expected_Event", "Observed_Nonevent", "Expected_Nonevent")
  
  return(list(partition = partition, stats = list(chi.sq = chi.sq, DF = n.bins - 2, p.value = p.value), RMSE = rmse))
}


```

```{r, message=FALSE, warning=FALSE}
out_HL <- HLfit2(model=bee_logit_model2, bin.method = "quantiles", n.bins = 10) # ok!

tibble::as.tibble(out_HL$partition)
```

```{r, message=FALSE, warning=FALSE}
out_HL$stats
```

\s\s

A título de ilustração, se utilizássemos a primeira função para o modelo expandido, a resposta seria diferente do que a saída do SAS - só teríamos 7 grupos/ intervalos:

```{r}
library(ResourceSelection)
help("hoslem.test")

out_HL2 <- hoslem.test(bee_logit_model2$y, bee_logit_model2$fitted.values)

# valores esperados -- ele agrupa os dois primeiros grupos de saida do SAS em um soh
tibble::as.tibble(cbind(matrix(out_HL2$expected[,2]), matrix(out_HL2$expected[,1]))) %>%
  tibble::rownames_to_column() %>%
  magrittr::set_colnames(c("grupo", "Expected_Nonevent", "Expected_Event"))
  


```



Em todos os testes que empregamos, o p-valor alto indica bom ajuste de nosso modelo - ou seja - não há diferenças significativas entre os valores preditos pelo modelo e os valores observados nos dados.


<!-- \s\s -->

<!-- ### ESTA CERTO FAZER ESTE TESTE PARA OS DADOS DE FREQUÊNCIA?? -->

<!-- O teste de Hosmer e Lemeshow ajusta as observações em categorias utilizando como padrão $n/10$ para cada categoria. No entanto, como só temos oito observações nos dados das abelhas, temos que fornecer via parâmetro `g` um número adequado de categorias para que se calcule os quantis. Como nossos dados tem apenas 8 observações, utilizamos `g=4`. O p-valor alto indica bom ajuste de nosso modelo - ou seja - não diferenças significativas entre os valores preditos pelo modelo e os valores observados nos dados. -->

\s\s

##### **Avaliando os resíduos**:

**Plots resíduos vs valores ajustados:**


<!-- para dividir a saida em 2 colunas com css-- eh a unica que funciona no browser!! -->
<!-- https://stackoverflow.com/questions/31753897/2-column-section-in-r-markdown -->
<!-- NAO FUNCIONA COM PLOTLY APENAS COM DYGRAPHS!!!! -->



```{r}
# outra forma de colocar os graficos lado a lado com plotly
# plotly::subplot(p2, p3)

```


```{r, fig.width=9}
# colcando tudo no mesmo gráfico

# se usarmos ~variavel ele traz os nomes das variaveis nos eixos
plotly::plot_ly(x = bee_logit_model$fitted.values, y = residuals(bee_logit_model), 
                      name = 'Deviance', type = 'scatter', mode = 'markers' ) %>%
  # plotly::layout(title = "Resíduos Deviance", xaxis = list(title="fitted"), yaxis = list(title="resíduos")) %>%
  plotly::add_trace(x = bee_logit_model$fitted.values, y = ~bee_logit_model$residuals, 
                      name = 'Pearson', type = 'scatter', mode = 'markers') %>%
  plotly::layout(title = "Resíduos", xaxis = list(title="fitted"), yaxis = list(title="resíduos") )
  
```

\s\s

Com intervalo de confiança:

```{r}
# library(plotly)
# library(broom)
# https://plot.ly/r/graphing-multiple-chart-types/#loess-smoother-with-uncertainty-bounds

m2 <- loess(residuals(bee_logit_model) ~ bee_logit_model$fitted.values)

p2 <- plotly::plot_ly(x = bee_logit_model$fitted.values, 
                      y = residuals(bee_logit_model)) %>% # nao posso colocar a cor aqui
  plotly::add_markers(marker = list( color = "blue"), name = "Deviance" ) %>% # tenho que adicionar uma cama especifica para alterar a cor
  plotly::add_lines(y = ~fitted(loess(residuals(bee_logit_model) ~ bee_logit_model$fitted.values)),
            line = list(color = 'rgba(138,43,226, 0.5)'), # o ultimo valor eh opacity
            # cores em decimal em: https://reeddesign.co.uk/test/namedcolors.html
            name = "Loess Smoother") %>% 
  plotly::add_ribbons(data = broom::augment(m2),
              ymin = ~.fitted - qnorm(0.975) * .se.fit,
              ymax = ~.fitted + qnorm(0.975) * .se.fit,
              line = list(color = 'rgba(138,43,226, 0.05)', opacity = 0.1),
              fillcolor = 'rgba(138,43,226, 0.2)', opacity = 0.25,
              name = "Standard Error") %>%
  plotly::layout(title = "Resíduos Deviance", 
                 xaxis = list(title="fitted"), 
                 yaxis = list(title="resíduos"))




m3 <- loess(bee_logit_model$residuals ~ bee_logit_model$fitted.values)

p3 <- plotly::plot_ly(x = bee_logit_model$fitted.values, y = bee_logit_model$residuals) %>%
  plotly::add_markers(marker = list( color = "orange"), name = "Pearson" ) %>% # tenho que adicionar uma cama especifica para alterar a cor
  plotly::add_lines(y = ~fitted(loess(bee_logit_model$residuals ~ bee_logit_model$fitted.values)),
            line = list(color = 'rgba(138,43,226, 0.5)'),
            name = "Loess Smoother") %>%
  plotly::add_ribbons(data = broom::augment(m3),
              ymin = ~.fitted - qnorm(0.975) * .se.fit,
              ymax = ~.fitted + qnorm(0.975) * .se.fit,
              line = list(color = 'rgba(138,43,226, 0.05)', opacity = 0.1),
              fillcolor = 'rgba(138,43,226, 0.2)', opacity = 0.25,
              name = "Standard Error") %>%
  plotly::layout(title = "Resíduos de Pearson", 
                 xaxis = list(title="fitted"), 
                 yaxis = list(title="resíduos"))


```



<div class = "row">
<div class = "col-md-6">

```{r, fig.height=4, fig.width=4.7}
p2
```

</div>
<div class = "col-md-6">

```{r, fig.height=4, fig.width=4.7}
p3
```

</div>
</div>


##### **Medidas (diagnóstico) de influência**


**Resíduos vs índices**

```{r, message=FALSE}
# ou com plotly:
library(dplyr)
# pontos e linhas no mesmo plot:
# https://plot.ly/r/line-and-scatter/

p2 <- plotly::plot_ly(x = 1:length(residuals(bee_logit_model)), y = residuals(bee_logit_model), 
                      name = 'prop', type = 'scatter', mode = 'markers', marker = list( color = "blue") ) %>%
  plotly::layout(title = "Resíduos Deviance", xaxis = list(title="índices"), yaxis = list(title="resíduos"))

p3 <- plotly::plot_ly(x = 1:length(residuals(bee_logit_model)), y = ~bee_logit_model$residuals, 
                      name = 'prop', type = 'scatter', mode = 'markers', marker = list( color = "green") )  %>%
  plotly::layout(title = "Resíduos de Pearson", xaxis = list(title="índices"), yaxis = list(title="resíduos"))
  
# se usarmos ~variavel ele traz os nomes das variaveis nos eixos
```


<div class = "row">
<div class = "col-md-6">

```{r, fig.height=4, fig.width=4}
p2
```

</div>
<div class = "col-md-6">

```{r, fig.height=4, fig.width=4}
p3
```

</div>
</div>



```{r}

medinflu <-influence.measures(bee_logit_model)
inf_measures <- tibble::as.tibble(medinflu$infmat)
inf_measures

```

\s\s
Plotando valores de leverage (*hat*), *dffit*, *dfbeta* (para dose) e *cook distance*:


```{r}
# separando as 4 medidas de interesse

inf_measures_sub <- inf_measures %>%
  dplyr::select(dfb.dose, dffit, cook.d, hat)

```


```{r}
# 1 plot para cada coluna
lista <- lapply(1:ncol(inf_measures_sub),
            function(j) {
              plotly::plot_ly(x = 1:nrow(inf_measures_sub),
                      y = as.data.frame(inf_measures_sub)[,j],
                      mode = "markers")
            })

```


**Gráficos para medidas de Influência:**

<div class = "row">
<div class = "col-md-6">

```{r, fig.height=4, fig.width=4.7, warning=FALSE, message=FALSE}
lista[[1]] %>%
  plotly::layout(title = "Dfbetas - Dose", xaxis = list(title="índices"), yaxis = list(title="dfbetas"))

lista[[3]] %>%
  plotly::layout(title = "Cook's Distance", xaxis = list(title="índices"), yaxis = list(title="cook"))
```

</div>
<div class = "col-md-6">

```{r, fig.height=4, fig.width=4.7, warning=FALSE, message=FALSE}
lista[[2]] %>%
  plotly::layout(title = "Dffit", xaxis = list(title="índices"), yaxis = list(title="dffit"))

lista[[4]] %>%
  plotly::layout(title = "Leverage (hat)", xaxis = list(title="índices"), yaxis = list(title="leverage"))
```

</div>
</div>


---

---

### Referências Bibliográficas

---


AGRESTI, ALAN. *An Introduction to Categorical Data Analysis*. John Wiley & Sons, second edition, 2007.

NOTAS DE AULA. *Análise de Dados Categorizados*. Curso de Graduação em Estatística, UnB, 2018.

R CORE TEAM. *R: A language and environment for statistical computing*. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.

---